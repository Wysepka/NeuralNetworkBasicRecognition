# Neural Network Basic Recognition

A C++ implementation of a neural network for pattern recognition, specifically designed for digit recognition using the MNIST dataset. This project demonstrates the fundamentals of neural network architecture, backpropagation, and machine learning concepts.

## âš ï¸ Project Status

**This project is currently not functional and has been discontinued.** The developer lost faith in debugging the application, though valuable learning was gained about C++ and neural networks during development.

## ğŸ—ï¸ Project Overview

This neural network implementation features:

- **Multi-layer perceptron** architecture
- **Backpropagation** algorithm for training
- **Parallel batch processing** capabilities
- **OpenGL-based visualization** using ImGui
- **MNIST dataset** integration for digit recognition
- **Modular design** with separate components for different functionalities

## ğŸ“ Project Structure

```
wysepka-neuralnetworkbasicrecognition/
â”œâ”€â”€ README.md
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ CMakePresets.json
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ Kaggle_Mnist/
â”‚       â”œâ”€â”€ t10k-images.idx3-ubyte
â”‚       â”œâ”€â”€ t10k-labels.idx1-ubyte
â”‚       â”œâ”€â”€ train-images.idx3-ubyte
â”‚       â””â”€â”€ train-labels.idx1-ubyte
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ Config/           # Configuration management
â”‚   â”œâ”€â”€ Core/             # Core enums and utilities
â”‚   â”œâ”€â”€ Data/             # Data handling and batching
â”‚   â”œâ”€â”€ Engine/           # Main engine coordination
â”‚   â”œâ”€â”€ Event/            # Message bus system
â”‚   â”œâ”€â”€ Loader/           # File loading utilities
â”‚   â”œâ”€â”€ Log/              # Logging system
â”‚   â”œâ”€â”€ Neural/           # Neural network core components
â”‚   â”œâ”€â”€ Rendering/        # OpenGL rendering system
â”‚   â””â”€â”€ Settings/         # Application settings
â”œâ”€â”€ lib/                  # External libraries
â”‚   â”œâ”€â”€ glad/            # OpenGL loader
â”‚   â”œâ”€â”€ glfw/            # Window management
â”‚   â”œâ”€â”€ glm/             # Mathematics library
â”‚   â”œâ”€â”€ imgui/           # Immediate mode GUI
â”‚   â””â”€â”€ MNISTReader/     # MNIST data reader
â”œâ”€â”€ NeuralNetwork_DigitRecognition/
â””â”€â”€ src/                 # Implementation files
    â””â”€â”€ private/
        â”œâ”€â”€ Config/
        â”œâ”€â”€ Data/
        â”œâ”€â”€ Engine/
        â”œâ”€â”€ Event/
        â”œâ”€â”€ Loader/
        â”œâ”€â”€ Log/
        â”œâ”€â”€ main/
        â”œâ”€â”€ Neural/
        â”œâ”€â”€ Rendering/
        â””â”€â”€ Settings/
```

## ğŸ§  Neural Network Architecture

### Core Components

1. **Layer System**
   - Input, Hidden, and Output layers
   - Configurable layer sizes
   - Weight and bias management
   - Gradient calculation and application

2. **Activation Functions**
   - Sigmoid
   - TanH (Hyperbolic Tangent)
   - ReLU (Rectified Linear Unit)
   - SiLU (Sigmoid Linear Unit)
   - Softmax

3. **Cost Functions**
   - Mean Squared Error (MSE)
   - Cross Entropy

4. **Training Features**
   - Batch processing
   - Parallel computation support
   - Learning rate decay
   - Momentum optimization
   - Weight decay

### Network Configuration

The neural network supports:
- Configurable input layer size (784 for MNIST)
- Multiple hidden layers with custom node counts
- Output layer with 10 nodes (digits 0-9)
- Batch size configuration
- Epoch count settings
- Parallel processing options

## ğŸ¯ Features

### Data Processing
- **MNIST Dataset Support**: Built-in support for MNIST digit recognition
- **Data Batching**: Efficient batch processing for large datasets
- **Data Normalization**: Automatic pixel value normalization
- **File Loading**: Robust file loading system with error handling

### Training System
- **Backpropagation**: Full implementation of backpropagation algorithm
- **Gradient Descent**: Optimized gradient descent with momentum
- **Learning Rate Scheduling**: Dynamic learning rate adjustment
- **Parallel Processing**: Multi-threaded batch processing
- **Progress Tracking**: Real-time training progress monitoring

### Visualization
- **OpenGL Rendering**: Hardware-accelerated graphics
- **ImGui Interface**: Modern, immediate mode GUI
- **Texture Display**: Real-time display of MNIST images
- **Training Visualization**: Live training progress and statistics

### System Architecture
- **Message Bus**: Event-driven architecture for component communication
- **Modular Design**: Clean separation of concerns
- **Configuration Management**: Flexible configuration system
- **Logging System**: Comprehensive logging capabilities

## ğŸ› ï¸ Technical Stack

### Core Technologies
- **C++17**: Modern C++ features and standards
- **CMake**: Cross-platform build system
- **OpenGL 4.6**: Graphics rendering
- **GLFW**: Window management and input handling

### External Libraries
- **GLAD**: OpenGL function loading
- **GLM**: Mathematics library
- **Dear ImGui**: Immediate mode GUI
- **MNIST Reader**: Dataset loading utilities

### Build System
- **CMake 3.10+**: Required minimum version
- **Ninja**: Build generator (optional)
- **MSVC/Clang**: Supported compilers

## ğŸš€ Building the Project

### Prerequisites
- C++17 compatible compiler
- CMake 3.10 or higher
- OpenGL 4.6 compatible graphics driver

### Build Instructions

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd wysepka-neuralnetworkbasicrecognition
   ```

2. **Configure with CMake**
   ```bash
   mkdir build
   cd build
   cmake ..
   ```

3. **Build the project**
   ```bash
   cmake --build .
   ```

### Build Presets

The project includes several CMake presets:
- `x64-debug`: 64-bit debug build
- `x64-release`: 64-bit release build
- `x86-debug`: 32-bit debug build
- `x86-release`: 32-bit release build

## ğŸ“Š Usage

### Running the Application

1. **Ensure MNIST data is present** in the `Data/Kaggle_Mnist/` directory
2. **Run the executable**:
   ```bash
   ./NeuralNetwork_DigitRecognition
   ```

### Configuration

The neural network can be configured through the `NeuralNetworkConfig` structure:

```cpp
// Example configuration
NeuralNetworkConfig config(
    784,                    // Input layer size
    hiddenLayers,          // Hidden layer configuration
    10,                    // Output layer size
    activationFunction,    // Activation function
    costFunction,          // Cost function
    batchSize,            // Batch size
    epochs,               // Number of epochs
    useParallel,          // Enable parallel processing
    maxParallelThreads,   // Maximum parallel threads
    logConfig            // Logging configuration
);
```

## ğŸ”§ Key Components

### Neural Network Core (`include/Neural/`)

- **`NeuralNetwork.h/cpp`**: Main network implementation
- **`Layer.h/cpp`**: Individual layer management
- **`LayerBuffer.h`**: Layer data buffers
- **`Activation.h`**: Activation function implementations
- **`Cost.h`**: Cost function implementations

### Data Management (`include/Data/`)

- **`NeuralDataFile.h/cpp`**: Data file handling
- **`NeuralDataBatch.h/cpp`**: Batch processing utilities

### Rendering System (`include/Rendering/`)

- **`RenderingSystem.h/cpp`**: OpenGL rendering engine
- **`TextureLoader.h/cpp`**: Texture loading and management
- **`UIRenderer.h/cpp`**: User interface rendering

### Event System (`include/Event/`)

- **`MessageBus.h/cpp`**: Event-driven communication
- **`Messages.h`**: Message definitions

## ğŸ“ˆ Performance Considerations

### Optimization Features
- **Parallel Batch Processing**: Multi-threaded training
- **Memory Management**: Efficient memory allocation
- **GPU Acceleration**: OpenGL-based rendering
- **Batch Normalization**: Improved training stability

### Known Limitations
- **Single-threaded Forward/Backward Pass**: Individual training iterations are sequential
- **Memory Usage**: Large datasets may require significant RAM
- **Training Time**: Complex networks may require extended training periods

## ğŸ› Known Issues

As mentioned in the project status, this implementation has several issues:

1. **Non-functional Training**: The neural network training process is not working correctly
2. **Debugging Challenges**: The developer encountered difficulties in debugging the application
3. **Architecture Complexity**: The modular design may have introduced integration issues

## ğŸ“š Learning Outcomes

Despite the project's non-functional status, valuable insights were gained:

- **C++ Modern Features**: Extensive use of C++17 features
- **Neural Network Theory**: Deep understanding of backpropagation and gradient descent
- **Software Architecture**: Event-driven design patterns
- **Graphics Programming**: OpenGL and ImGui integration
- **Build Systems**: CMake configuration and cross-platform development

## ğŸ¤ Contributing

While this project is discontinued, the codebase serves as a valuable learning resource for:

- Neural network implementation concepts
- C++ software architecture patterns
- Graphics programming with OpenGL
- Event-driven system design

## ğŸ“„ License

This project is provided as-is for educational purposes. Please refer to the original repository for licensing information.

## ğŸ™ Acknowledgments

- **MNIST Dataset**: Standard benchmark for digit recognition
- **OpenGL Community**: Graphics programming resources
- **Dear ImGui**: Excellent immediate mode GUI library
- **GLFW**: Cross-platform window management

---

*This README documents the project structure and implementation details for educational purposes. The project itself is not functional but provides valuable insights into neural network implementation and C++ software development.* 
